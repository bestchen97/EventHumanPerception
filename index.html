<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Event-based Human Perception.">
  <meta name="keywords" content="Event, Human Pose Estimation, Human Action Recognition">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Efficient Human Pose Estimation via 3D Event Point Cloud</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>






<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Efficient Human Pose Estimation via 3D Event Point Cloud</h1>
          <h2 class="title is-4">3DV'2022</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jiaan Chen<sup>1,*</sup>,</span>
	    <span class="author-block">
              Hao Shi<sup>1,*</sup>,
            </span>
            <span class="author-block">
              Yaozu Ye<sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yangkailun.com">Kailun Yang</a><sup>2</sup>,
            </span>
	    <span class="author-block">
              <a href="https://ahupujr.github.io">Lei Sun</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://wangkaiwei.org">Kaiwei Wang</a><sup>1,+</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Zhejiang University,</span>
            <span class="author-block"><sup>2</sup>KIT,</span>
            <span class="author-block"><sup>3</sup>ETH Zurich,</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2206.04511"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2206.04511"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/MasterHow/EventPointPose"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <p style="text-align: center;">
      <img src="./figures/paradigm.png"
      class="model"
      alt="paradigm image."
      width="80%"/>
      <h2 class="subtitle has-text-centered">
        2D event frame based human pose estimation paradigm vs. the proposed novel 3D event point cloud based paradigm.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">

          <p>
            Human Pose Estimation (HPE) aims to predict the keypoints of each person from perceived signals. 
	    RGB frames based HPE has experienced a rapid development benefiting from deep learning. 
	    While it still meets challenges with the drawbacks of frame-based cameras. The prediction of keypoints in scenarios with motion blur 
	    or high dynamic range will be inaccurate.
          </p>
          <p>
	    Event cameras, such as the Dynamic Vision Sensor (DVS), is a kind of bio-inspired 
	    asynchronous sensor responding to changes in brightness on each pixel independently, with higher dynamic range (over 100dB) and 
	    larger temporal resolution (in the order of us). Event cameras can tackle the disadvantages of frame-based cameras, 
	    which could maintain stable output in such extreme scenes.
	    Event-based HPE has not been fully studied, which remains great potential for applications in extreme scenes 
	    and efficiency-critical conditions. In this project, we are the first to estimate 2D human pose directly from 3D event point cloud. 
          </p>
          <p>
            We explore the feasibility of estimating human pose from 3D event point clouds directly, which is the first work from this perspective to our best knowledge.
	    We demonstrate the effectiveness of well-known LiDAR point cloud learning backbones for event point cloud based human pose estimation.
	    We propose a new event representation‚Äìrasterized event point cloud, which maintains the 3D features from multiple statistical cues 
	    and significantly reduces memory consumption and computational overhead with the same precision.
          </p>
          <p>
            Our method based on PointNet with 2048 points input achieves 82.46mm in MPJPE3D on the <a href="https://github.com/SensorsINI/DHP19">DHP19 dataset</a>, 
	    while only has a latency of 12.29ms on an NVIDIA Jetson Xavier NX edge computing platform, 
	    which is ideally suitable for real-time detection with event cameras.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Modules -->
    <section class="section">
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <h2 class="title is-3">Pipeline</h2>
        <div class="hero-body">
          <img src="./figures/pipeline.png"
          class="model"
          alt="pipeline image."/>
          <h2 class="subtitle has-text-justified">
            <p>
              The raw 3D event point cloud is first rasterized, and then processed by the point cloud backbone. The 
	      features output from the backbone are then connected to linear layers to predict two vectors. 
	      2D positions of human keypoints are proposed via decoding the two vectors. 
	      Our methods can be easily deployed and integrated to work with different 3D learning architectures, adapted to event-based HPE.
	      We test PointNet, DGCNN, and Point Transformer in our work.
            </p>
          </h2>
        </div>

        <h2 class="title is-3">Event Representation</h2>
        <div class="columns is-centered">
        <div class="column is-full-width">
          <p style="text-align: center;">
          <img src="./figures/rasterization.png"
          class="model"
          alt="rasterization image."
          width="90%"/>
         </p>
          <h2 class="subtitle has-text-centered">
          <b>Schematic diagram of event point cloud rasterization.</b> (a) Raw 3D event point cloud input, (b) Time slice of event point cloud,
          (c) Rasterized event point cloud at (x; y) position. Note that the rasterization process preserves the discrete nature of the point cloud, rather
          than the 2D image.
          </h2>
        </div>
        </div>
      </div>
    </section>
    <!-- Modules -->


    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Comparison Results</h3>
         <div class="hero-body">
          <img src="./figures/visualization.png"
           class="model"
           alt="visualization image."
	   width="90%"/>
         </div>

         <h3 class="title is-4">PointNet-4096 Results on DHP19</h3>
         <div class="hero-body">
          <h2 class="subtitle has-text-justified">
            <span style="width: 80px;; display:inline-block"> </span> 
            <b>sub13_session4_mov1</b>
            <span style="width: 140px;; display:inline-block"> </span> 
            <b>sub15_session4_mov2</b>             
        </h2>
        <div class="column content">
	    <span style="width: 80px;; display:inline-block"> </span> 
          <img src="./figures/sub13_session4_mov1_3D.gif"
           class="model"
           alt="model image."
	   width="50%"/>
             <h2 class="subtitle has-text-centered">
             
          </h2>
         </div>
	      
         <div class="column content">
	   <span style="width: 140px;; display:inline-block"> </span> 
          <img src="./figures/sub15_session4_mov2_3D.gif"
           class="model"
           alt="model image."
	   width="50%"/>
             <h2 class="subtitle has-text-centered">
             
          </h2>
         </div>

      </div>
    </div>


  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{chen2022EPP,
  	title={Efficient Human Pose Estimation via 3D Event Point Cloud},
  	author={Chen, Jiaan and Shi, Hao and Ye, Yaozu and Yang, Kailun and Sun, Lei and Wang, Kaiwei},
  	booktitle={2022 International Conference on 3D Vision (3DV)},
  	year={2022}
	}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2112.04511">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/MasterHow/EventPointPose" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
